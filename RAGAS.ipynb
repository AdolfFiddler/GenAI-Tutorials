{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Anubhav\\AppData\\Local\\Temp\\ipykernel_18324\\3748963309.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  loader = PyPDFLoader(\".\\data\\RAG.pdf\")\n",
      "c:\\Users\\Anubhav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pypdf\\_crypt_providers\\_cryptography.py:32: CryptographyDeprecationWarning: ARC4 has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.ARC4 and will be removed from this module in 48.0.0.\n",
      "  from cryptography.hazmat.primitives.ciphers.algorithms import AES, ARC4\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\".\\data\\RAG.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHunking\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter  = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap = 100,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '.\\\\data\\\\RAG.pdf', 'page': 0}, page_content='eration, natural language processing, information retrieval\\nI. I NTRODUCTION\\nLARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anubhav\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_validation.py:26: UserWarning: Unsupported Windows version (11). ONNX Runtime supports Windows 10 and above, only.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setting up the vector store\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    collection_name = 'evaluation',\n",
    "    embedding = OpenAIEmbeddings()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 1, 'source': '.\\\\data\\\\RAG.pdf'}, page_content='RAG, and Modular RAG, as showed in Figure 3. Despite\\nRAG method are cost-effective and surpass the performance\\nof the native LLM, they also exhibit several limitations.\\nThe development of Advanced RAG and Modular RAG is\\na response to these specific shortcomings in Naive RAG.\\nA. Naive RAG\\nThe Naive RAG research paradigm represents the earli-\\nest methodology, which gained prominence shortly after the'),\n",
       " Document(metadata={'page': 15, 'source': '.\\\\data\\\\RAG.pdf'}, page_content='external knowledge bases. The survey showcases the evolution\\nof RAG technologies and their application on many different\\ntasks. The analysis outlines three developmental paradigms\\nwithin the RAG framework: Naive, Advanced, and Modu-\\nlar RAG, each representing a progressive enhancement over\\nits predecessors. RAG’s technical integration with other AI\\nmethodologies, such as fine-tuning and reinforcement learning,\\nhas further expanded its capabilities. Despite the progress in\\nRAG technology, there are research opportunities to improve\\nits robustness and its ability to handle extended contexts.\\nRAG’s application scope is expanding into multimodal do-\\nmains, adapting its principles to interpret and process diverse\\ndata forms like images, videos, and code. This expansion high-\\nlights RAG’s significant practical implications for AI deploy-\\nment, attracting interest from academic and industrial sectors.'),\n",
       " Document(metadata={'page': 3, 'source': '.\\\\data\\\\RAG.pdf'}, page_content='principles of Advanced and Naive RAG, illustrating a progres-\\nsion and refinement within the RAG family.\\n1) New Modules: The Modular RAG framework introduces\\nadditional specialized components to enhance retrieval and\\nprocessing capabilities. The Search module adapts to spe-\\ncific scenarios, enabling direct searches across various data\\nsources like search engines, databases, and knowledge graphs,\\nusing LLM-generated code and query languages [15]. RAG-\\nFusion addresses traditional search limitations by employing\\na multi-query strategy that expands user queries into diverse\\nperspectives, utilizing parallel vector searches and intelligent\\nre-ranking to uncover both explicit and transformative knowl-\\nedge [16]. The Memory module leverages the LLM’s memory\\nto guide retrieval, creating an unbounded memory pool that'),\n",
       " Document(metadata={'page': 7, 'source': '.\\\\data\\\\RAG.pdf'}, page_content='edge retrieval and reasoning problems in a multi-document\\nenvironment.\\nC. Query Optimization\\nOne of the primary challenges with Naive RAG is its\\ndirect reliance on the user’s original query as the basis for\\nretrieval. Formulating a precise and clear question is difficult,\\nand imprudent queries result in subpar retrieval effectiveness.\\nSometimes, the question itself is complex, and the language\\nis not well-organized. Another difficulty lies in language\\ncomplexity ambiguity. Language models often struggle when\\ndealing with specialized vocabulary or ambiguous abbrevi-\\nations with multiple meanings. For instance, they may not\\ndiscern whether “LLM” refers to large language model or a\\nMaster of Laws in a legal context.\\n1) Query Expansion: Expanding a single query into mul-\\ntiple queries enriches the content of the query, providing\\nfurther context to address any lack of specific nuances, thereby\\nensuring the optimal relevance of the generated answers.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking on our retriever\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 4})\n",
    "retriever.invoke(\"What is Naive RAG?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "\n",
    "# Prompt\n",
    "prompt_template = \"\"\"You are an assistant for question-answering tasks who answers questions based \n",
    "only on the context that are provided to you.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Follow these instructions strictly:\n",
    "\n",
    "- Use three sentences maximum and keep the answer concise.\n",
    "- Do not make up anything from your end, only refer to the context provided for answer generation\n",
    "- If the context doesn't have required information to answer the question, respond with \"I do not know\"\n",
    "\n",
    "question: {question}\n",
    "search_results: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# llm \n",
    "\n",
    "llm = ChatOpenAI(model = 'gpt-4o')\n",
    "\n",
    "# combining the retrieved docs\n",
    "def format_docs(docs):\n",
    "    if not docs:\n",
    "        return \"\"\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs if doc.page_content)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {'context': retriever | format_docs , 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Naive RAG represents the earliest methodology within the RAG framework, which gained prominence shortly after its inception. It relies directly on the user's original query for retrieval, which can lead to subpar effectiveness if the query is not precise or clear. Challenges include difficulty in handling complex or ambiguous language and specialized vocabulary.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(input = \"What is Naive RAG?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with Self Generated Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Reading the Human Generated Test Set\n",
    "df = pd.read_csv(\"./data/testset.csv\", delimiter = '|')\n",
    "questions = df[\"question\"].tolist()\n",
    "ground_truth = df[\"ground_truth\"].tolist()\n",
    "\n",
    "# Setting up the schema for eval dataset\n",
    "data = {\"question\": [], \"answer\": [], \"contexts\": [], \"ground_truth\": ground_truth}\n",
    "\n",
    "# Creating food for eval dataset\n",
    "for query in questions:\n",
    "    # The question\n",
    "    data[\"question\"].append(query)\n",
    "    # The Rag generated answer\n",
    "    data[\"answer\"].append(rag_chain.invoke(input = query))\n",
    "    # The retrieved contexts\n",
    "    data[\"contexts\"].append(\n",
    "        [doc.page_content for doc in retriever.invoke(query)]\n",
    "    )\n",
    "\n",
    "dataset = Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see this dataset in a df format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Retrieval-Augmented Generation (RAG)?</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) is a tech...</td>\n",
       "      <td>[1\\nRetrieval-Augmented Generation for Large\\n...</td>\n",
       "      <td>RAG enhances LLMs by incorporating knowledge f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three main paradigms of RAG?</td>\n",
       "      <td>The three main paradigms of RAG are Naive RAG,...</td>\n",
       "      <td>[external knowledge bases. The survey showcase...</td>\n",
       "      <td>The three main paradigms of RAG are Naive RAG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the primary purpose of RAG in large la...</td>\n",
       "      <td>The primary purpose of Retrieval-Augmented Gen...</td>\n",
       "      <td>[2\\nFig. 1. Technology tree of RAG research. T...</td>\n",
       "      <td>The primary purpose is to reduce hallucination...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What are the three core components of RAG?</td>\n",
       "      <td>The three core components of RAG are \"Retrieva...</td>\n",
       "      <td>[ponents intricately collaborate to form a coh...</td>\n",
       "      <td>The core components of RAG are Retrieval, Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the drawback of Naive RAG in the retri...</td>\n",
       "      <td>The drawback of Naive RAG in the retrieval pha...</td>\n",
       "      <td>[4\\nFig. 3. Comparison between the three parad...</td>\n",
       "      <td>Naive RAG struggles with precision and recall,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      What is Retrieval-Augmented Generation (RAG)?   \n",
       "1          What are the three main paradigms of RAG?   \n",
       "2  What is the primary purpose of RAG in large la...   \n",
       "3         What are the three core components of RAG?   \n",
       "4  What is the drawback of Naive RAG in the retri...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Retrieval-Augmented Generation (RAG) is a tech...   \n",
       "1  The three main paradigms of RAG are Naive RAG,...   \n",
       "2  The primary purpose of Retrieval-Augmented Gen...   \n",
       "3  The three core components of RAG are \"Retrieva...   \n",
       "4  The drawback of Naive RAG in the retrieval pha...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [1\\nRetrieval-Augmented Generation for Large\\n...   \n",
       "1  [external knowledge bases. The survey showcase...   \n",
       "2  [2\\nFig. 1. Technology tree of RAG research. T...   \n",
       "3  [ponents intricately collaborate to form a coh...   \n",
       "4  [4\\nFig. 3. Comparison between the three parad...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  RAG enhances LLMs by incorporating knowledge f...  \n",
       "1  The three main paradigms of RAG are Naive RAG,...  \n",
       "2  The primary purpose is to reduce hallucination...  \n",
       "3  The core components of RAG are Retrieval, Gene...  \n",
       "4  Naive RAG struggles with precision and recall,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(dataset)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how RAGAS treats a Single Turn Sample for evaluation and then we can scale it up for the entire test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting contexts for the question\n",
    "contexts = []\n",
    "for i in retriever.invoke(\"What is Retrieval-Augmented Generation (RAG)?\"):\n",
    "    contexts.append(i.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user_input': 'What is Retrieval-Augmented Generation (RAG)?', 'retrieved_contexts': ['1\\nRetrieval-Augmented Generation for Large\\nLanguage Models: A Survey\\nYunfan Gaoa, Yun Xiongb, Xinyu Gaob, Kangxiang Jiab, Jinliu Panb, Yuxi Bic, Yi Daia, Jiawei Suna, Meng\\nWangc, and Haofen Wanga,c\\naShanghai Research Institute for Intelligent Autonomous Systems, Tongji University\\nbShanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\\ncCollege of Design and Innovation, Tongji University\\nAbstract —Large Language Models (LLMs) showcase impres-\\nsive capabilities but encounter challenges like hallucination,\\noutdated knowledge, and non-transparent, untraceable reasoning\\nprocesses. Retrieval-Augmented Generation (RAG) has emerged\\nas a promising solution by incorporating knowledge from external\\ndatabases. This enhances the accuracy and credibility of the\\ngeneration, particularly for knowledge-intensive tasks, and allows\\nfor continuous knowledge updates and integration of domain-\\nspecific information. RAG synergistically merges LLMs’ intrin-', 'eration, natural language processing, information retrieval\\nI. I NTRODUCTION\\nLARGE language models (LLMs) have achieved remark-\\nable success, though they still face significant limitations,\\nespecially in domain-specific or knowledge-intensive tasks [1],\\nnotably producing “hallucinations” [2] when handling queries\\nbeyond their training data or requiring current information. To\\novercome challenges, Retrieval-Augmented Generation (RAG)\\nenhances LLMs by retrieving relevant document chunks from\\nexternal knowledge base through semantic similarity calcu-\\nlation. By referencing external knowledge, RAG effectively\\nreduces the problem of generating factually incorrect content.\\nIts integration into LLMs has resulted in widespread adoption,\\nestablishing RAG as a key technology in advancing chatbots\\nand enhancing the suitability of LLMs for real-world applica-\\ntions.\\nRAG technology has rapidly developed in recent years, and\\nthe technology tree summarizing related research is shown', 'Augmentation Hurdles . Integrating retrieved information\\nwith the different task can be challenging, sometimes resulting\\nin disjointed or incoherent outputs. The process may also\\nencounter redundancy when similar information is retrieved\\nfrom multiple sources, leading to repetitive responses. Deter-\\nmining the significance and relevance of various passages and\\nensuring stylistic and tonal consistency add further complexity.\\nFacing complex issues, a single retrieval based on the original\\nquery may not suffice to acquire adequate context information.\\nMoreover, there’s a concern that generation models might\\noverly rely on augmented information, leading to outputs that\\nsimply echo retrieved content without adding insightful or\\nsynthesized information.\\nB. Advanced RAG\\nAdvanced RAG introduces specific improvements to over-\\ncome the limitations of Naive RAG. Focusing on enhancing re-\\ntrieval quality, it employs pre-retrieval and post-retrieval strate-', '11\\nFig. 5. In addition to the most common once retrieval, RAG also includes three types of retrieval augmentation processes. (left) Iterative retrieval involves\\nalternating between retrieval and generation, allowing for richer and more targeted context from the knowledge base at each step. (Middle) Recursive retrieval\\ninvolves gradually refining the user query and breaking down the problem into sub-problems, then continuously solving complex problems through retrieval\\nand generation. (Right) Adaptive retrieval focuses on enabling the RAG system to autonomously determine whether external knowledge retrieval is necessary\\nand when to stop retrieval and generation, often utilizing LLM-generated special tokens for control.\\nbase for LLMs. This approach has been shown to enhance\\nthe robustness of subsequent answer generation by offering\\nadditional contextual references through multiple retrieval\\niterations. However, it may be affected by semantic discon-'], 'response': 'Retrieval-Augmented Generation (RAG) is a method that enhances large language models (LLMs) by incorporating knowledge from external databases. This approach improves accuracy and credibility, particularly for knowledge-intensive tasks, by retrieving relevant information to reduce the occurrence of factually incorrect content. RAG allows for continuous updates and domain-specific information integration, making it a key technology for advancing chatbots and real-world applications.', 'reference': 'RAG enhances LLMs by incorporating knowledge from external databases, improving accuracy and credibility for knowledge-intensive tasks.'}\n"
     ]
    }
   ],
   "source": [
    "# Creating a single turn sample\n",
    "\n",
    "from ragas import SingleTurnSample\n",
    "\n",
    "# Creating a single turn sample object\n",
    "sample = SingleTurnSample(\n",
    "    user_input=\"What is Retrieval-Augmented Generation (RAG)?\",\n",
    "    reference=\"RAG enhances LLMs by incorporating knowledge from external databases, improving accuracy and credibility for knowledge-intensive tasks.\",\n",
    "    retrieved_contexts=contexts,\n",
    "    response = rag_chain.invoke(\"What is Retrieval-Augmented Generation (RAG)?\"))\n",
    "\n",
    "print(sample.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithReference,\n",
    "    LLMContextRecall,\n",
    "    ContextEntityRecall,\n",
    "    NoiseSensitivity,\n",
    "    ResponseRelevancy,\n",
    "    Faithfulness,\n",
    ")\n",
    "\n",
    "\n",
    "embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n",
    "\n",
    "# Defining each metric that we wanna see\n",
    "metrics = {\n",
    "        \"Context Precision\": LLMContextPrecisionWithReference(llm=llm),\n",
    "        \"Context Recall\": LLMContextRecall(llm=llm),\n",
    "        \"Context Entities Recall\": ContextEntityRecall(llm=llm),\n",
    "        \"Noise Sensitivity\": NoiseSensitivity(llm=llm),\n",
    "        \"Response Relevancy\": ResponseRelevancy(llm=llm,embeddings=OpenAIEmbeddings()),\n",
    "        \"Faithfulness\": Faithfulness(llm=llm),\n",
    "    }\n",
    "\n",
    "# Define a function to evaluate all metrics for a sample\n",
    "def evaluate_metrics(sample: SingleTurnSample, metrics:dict):\n",
    "    # Results dictionary to store the metric values\n",
    "    results = {}\n",
    "    # Iterating through the metrics dictionary\n",
    "    for metric_name, metric in metrics.items():\n",
    "\n",
    "        try:\n",
    "            results[metric_name] = metric.single_turn_score(sample)\n",
    "\n",
    "        except Exception as e:\n",
    "            results[metric_name] = f\"Error: {e}\"\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Context Precision': 0.9166666666361111,\n",
       " 'Context Recall': 1.0,\n",
       " 'Context Entities Recall': 0.3333333322222222,\n",
       " 'Noise Sensitivity': 0.5555555555555556,\n",
       " 'Response Relevancy': 0.9463667521553832,\n",
       " 'Faithfulness': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = evaluate_metrics(sample = sample, metrics = metrics)\n",
    "results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale this up to get each of our test case evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate each row\n",
    "\n",
    "def evaluate_row(row, metrics):\n",
    "    \"\"\"\n",
    "    Creates a single turn sample for the row\n",
    "    Evaluates all metrics for it\n",
    "    Returns a dictionary containing all metrics\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a SingleTurnSample for every row\n",
    "    sample = SingleTurnSample(\n",
    "        user_input=row['question'],\n",
    "        reference=row['ground_truth'],\n",
    "        retrieved_contexts=row['contexts'],\n",
    "        response = row['answer']\n",
    "    )\n",
    "    \n",
    "    # Evaluate metrics for the sample\n",
    "    results = {}\n",
    "    for metric_name, metric in metrics.items():\n",
    "        try:\n",
    "            results[metric_name] = metric.single_turn_score(sample)\n",
    "        except Exception as e:\n",
    "            results[metric_name] = f\"Error: {e}\"\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to evaluate the entire dataframe of testset\n",
    "\n",
    "def evaluate_dataframe(df, metrics):\n",
    "    \"\"\"\n",
    "    Iterates through the df test set\n",
    "    For every row uses evaluate_row function to get result dictionary\n",
    "    Append each dictionary to a list\n",
    "    Uses list to create the result dataframe\n",
    "\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for _, row in df.iterrows():\n",
    "        row_results = evaluate_row(row, metrics)\n",
    "        results.append(row_results)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = evaluate_dataframe(df1[:3],metrics = metrics) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Context Precision</th>\n",
       "      <th>Context Recall</th>\n",
       "      <th>Context Entities Recall</th>\n",
       "      <th>Noise Sensitivity</th>\n",
       "      <th>Response Relevancy</th>\n",
       "      <th>Faithfulness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.946367</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.953538</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Context Precision  Context Recall  Context Entities Recall  \\\n",
       "0           0.916667             1.0                 0.333333   \n",
       "1           1.000000             1.0                 1.000000   \n",
       "2           0.500000             0.0                 0.000000   \n",
       "\n",
       "   Noise Sensitivity  Response Relevancy  Faithfulness  \n",
       "0           0.583333            0.946367           1.0  \n",
       "1           0.000000            1.000000           1.0  \n",
       "2           1.000000            0.953538           1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Retrieval-Augmented Generation (RAG)?</td>\n",
       "      <td>Retrieval-Augmented Generation (RAG) is a tech...</td>\n",
       "      <td>[1\\nRetrieval-Augmented Generation for Large\\n...</td>\n",
       "      <td>RAG enhances LLMs by incorporating knowledge f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the three main paradigms of RAG?</td>\n",
       "      <td>The three main paradigms of RAG are Naive RAG,...</td>\n",
       "      <td>[external knowledge bases. The survey showcase...</td>\n",
       "      <td>The three main paradigms of RAG are Naive RAG,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the primary purpose of RAG in large la...</td>\n",
       "      <td>The primary purpose of Retrieval-Augmented Gen...</td>\n",
       "      <td>[2\\nFig. 1. Technology tree of RAG research. T...</td>\n",
       "      <td>The primary purpose is to reduce hallucination...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0      What is Retrieval-Augmented Generation (RAG)?   \n",
       "1          What are the three main paradigms of RAG?   \n",
       "2  What is the primary purpose of RAG in large la...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  Retrieval-Augmented Generation (RAG) is a tech...   \n",
       "1  The three main paradigms of RAG are Naive RAG,...   \n",
       "2  The primary purpose of Retrieval-Augmented Gen...   \n",
       "\n",
       "                                            contexts  \\\n",
       "0  [1\\nRetrieval-Augmented Generation for Large\\n...   \n",
       "1  [external knowledge bases. The survey showcase...   \n",
       "2  [2\\nFig. 1. Technology tree of RAG research. T...   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  RAG enhances LLMs by incorporating knowledge f...  \n",
       "1  The three main paradigms of RAG are Naive RAG,...  \n",
       "2  The primary purpose is to reduce hallucination...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.iloc[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())\n",
    "llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-3.5-turbo\"))\n",
    "generator = TestsetGenerator(llm=llm, embedding_model=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_size = 10  # Number of samples to generate\n",
    "\n",
    "testset = generator.generate_with_langchain_docs(chunks, testset_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
